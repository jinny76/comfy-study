# ComfyUI 模型使用指南

## 模型类型总览

| 类型 | 目录 | 用途 | 格式 |
|------|------|------|------|
| Checkpoint | `models/checkpoints/` | 主模型 | .safetensors, .ckpt |
| VAE | `models/vae/` | 图像编解码 | .safetensors |
| LoRA | `models/loras/` | 风格/角色微调 | .safetensors |
| ControlNet | `models/controlnet/` | 控制生成 | .safetensors |
| CLIP | `models/clip/` | 文本编码器 | .safetensors |
| UNet | `models/unet/` | 单独的扩散模型 | .safetensors |
| Embedding | `models/embeddings/` | 文本嵌入 | .pt, .safetensors |
| Upscaler | `models/upscale_models/` | 图片放大 | .pth |

## 图像生成模型

### Stable Diffusion 1.5

**特点**: 经典模型，资源消耗低，生态最丰富

| 项目 | 值 |
|------|-----|
| 显存需求 | 4GB+ |
| 推荐尺寸 | 512x512, 512x768 |
| 潜空间 | 4通道 |

**推荐模型**:
- [Realistic Vision](https://civitai.com/models/4201) - 写实人像
- [DreamShaper](https://civitai.com/models/4384) - 多风格
- [MeinaMix](https://civitai.com/models/7240) - 动漫

**LoRA 资源最丰富的版本。**

---

### Stable Diffusion XL (SDXL)

**特点**: 高分辨率，细节更好，需要更多显存

| 项目 | 值 |
|------|-----|
| 显存需求 | 8GB+ |
| 推荐尺寸 | 1024x1024, 896x1152 |
| 潜空间 | 4通道 |

**推荐模型**:
- [SDXL Base](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0) - 官方基础
- [RealVisXL](https://civitai.com/models/139562) - 写实
- [Animagine XL](https://civitai.com/models/260267) - 动漫
- [Juggernaut XL](https://civitai.com/models/133005) - 综合

**节点**: Load Checkpoint (标准)

---

### Stable Diffusion 3 / 3.5

**特点**: 最新架构，文字渲染能力强

| 项目 | 值 |
|------|-----|
| 显存需求 | 10GB+ |
| 推荐尺寸 | 1024x1024 |
| 潜空间 | 16通道 |

**模型变体**:
- SD3 Medium - 中等大小
- SD3.5 Large - 完整版
- SD3.5 Large Turbo - 加速版

**需要三个 CLIP**:
- clip_g (OpenCLIP ViT-bigG)
- clip_l (OpenAI CLIP ViT-L)
- t5xxl (T5-XXL 文本编码器)

**节点**: 使用专门的 SD3 节点或配置 Triple CLIP Loader

---

### Flux

**特点**: Black Forest Labs 出品，质量极高

| 项目 | 值 |
|------|-----|
| 显存需求 | 12GB+ (量化后 8GB) |
| 推荐尺寸 | 1024x1024 |
| 潜空间 | 16通道 |

**模型变体**:
- Flux.1 Dev - 开发版 (需授权)
- Flux.1 Schnell - 快速版 (Apache 2.0)

**加载方式**:
```
UNET Loader ──▶ Flux 模型
CLIP Loader ──▶ clip_l + t5xxl
VAE Loader  ──▶ Flux VAE
```

**量化版本** (省显存):
- flux1-dev-Q8_0.gguf (8GB)
- flux1-dev-Q4_K_S.gguf (6GB)

---

### PixArt / HunyuanDiT

**特点**: 国产模型，中文理解好

**PixArt**:
- PixArt-α: 初版
- PixArt-Σ: 改进版

**HunyuanDiT** (混元):
- 1.2B 参数
- 中英双语支持

## 视频生成模型

### HunyuanVideo

| 项目 | 值 |
|------|-----|
| 显存需求 | 24GB+ (量化后 12GB) |
| 输出 | 视频 |

**模型组件**:
- hunyuan_video.safetensors
- hunyuan_video_vae.safetensors
- clip_l + llava_llama3

---

### Mochi

| 项目 | 值 |
|------|-----|
| 显存需求 | 24GB+ |
| 特点 | 运动流畅 |

---

### Wan 2.1

**腾讯出品的视频模型**:
- 1.3B / 14B 参数版本
- 支持文生视频、图生视频

---

### LTXV

轻量级视频模型，资源消耗相对较低。

## LoRA 使用

### 什么是 LoRA

Low-Rank Adaptation，小体积微调模型：
- 体积小 (几十MB ~ 几百MB)
- 可叠加使用
- 针对特定风格/角色/概念

### 使用方法

```
Load Checkpoint ──▶ Load LoRA ──▶ ...
                        │
                strength_model: 0.8  (模型强度)
                strength_clip: 0.8   (CLIP强度)
```

### LoRA 叠加

多个 LoRA 串联:
```
Checkpoint ──▶ LoRA 1 ──▶ LoRA 2 ──▶ LoRA 3 ──▶ KSampler
```

**注意**: 叠加太多可能导致画面崩坏，建议降低单个强度。

### LoRA 来源

- [Civitai](https://civitai.com/) - 最大的模型社区
- [LiblibAI](https://www.liblib.art/) - 国内社区
- [HuggingFace](https://huggingface.co/) - 开源模型

## ControlNet

### 控制类型

| 类型 | 用途 | 预处理 |
|------|------|--------|
| Canny | 边缘控制 | Canny Edge |
| Depth | 深度控制 | Depth Anything |
| OpenPose | 姿态控制 | OpenPose |
| Lineart | 线稿控制 | Lineart |
| Scribble | 涂鸦控制 | Scribble |
| Softedge | 柔和边缘 | HED/Pidinet |
| Tile | 细节增强 | - |
| IP-Adapter | 图像风格 | - |

### 模型匹配

| 基础模型 | ControlNet 版本 |
|----------|-----------------|
| SD 1.5 | controlnet-v1-1 |
| SDXL | controlnet-sdxl |
| Flux | flux-controlnet |

### 使用流程

```
控制图 ──▶ 预处理器 ──▶ Apply ControlNet ──▶ KSampler
                              │
                          strength: 0.8
                          start_percent: 0.0
                          end_percent: 1.0
```

## IP-Adapter

用图片控制生成风格：

```
参考图 ──▶ IP-Adapter ──┐
                        │
提示词 ──▶ CLIP ────────┼──▶ KSampler
                        │
模型 ────────────────────┘
```

**模型版本**:
- ip-adapter_sd15 / ip-adapter-plus_sd15
- ip-adapter_sdxl / ip-adapter-plus_sdxl

## VAE 模型

### 何时需要单独 VAE

大多数情况下 Checkpoint 自带 VAE，但有时需要替换：
- 颜色发灰 → 换更好的 VAE
- 特殊模型 (如 Flux) 需要配套 VAE

### 推荐 VAE

| 模型 | VAE |
|------|-----|
| SD 1.5 | vae-ft-mse-840000 |
| SDXL | sdxl_vae |
| Flux | ae.safetensors |

## 模型下载

### 下载源

| 来源 | 地址 | 特点 |
|------|------|------|
| HuggingFace | huggingface.co | 官方模型 |
| Civitai | civitai.com | 社区模型最多 |
| 魔搭 | modelscope.cn | 国内镜像 |
| HF镜像 | hf-mirror.com | 国内加速 |

### 使用本仓库下载工具

```bash
python tools/download_models.py \
    "https://huggingface.co/xxx/model.safetensors" \
    --output models/checkpoints/

# 断点续传
python tools/download_models.py -r
```

### 模型格式

| 格式 | 说明 |
|------|------|
| .safetensors | 推荐，安全快速 |
| .ckpt | 旧格式，可能有安全风险 |
| .gguf | 量化格式，省显存 |
| .bin | PyTorch 原生格式 |

## 模型放置

确保模型放在正确目录：

```
ComfyUI/
└── models/
    ├── checkpoints/     ← 主模型
    │   ├── sd15.safetensors
    │   └── sdxl.safetensors
    ├── vae/            ← VAE
    ├── loras/          ← LoRA
    ├── controlnet/     ← ControlNet
    ├── clip/           ← CLIP 文本编码器
    ├── unet/           ← 单独的 UNet (Flux等)
    └── upscale_models/ ← 放大模型
```

## 模型配置文件

`extra_model_paths.yaml` 可配置额外模型路径：

```yaml
# 共享 A1111 模型
a1111:
    base_path: D:/stable-diffusion-webui/

    checkpoints: models/Stable-diffusion
    vae: models/VAE
    loras: models/Lora
    embeddings: embeddings

# 自定义路径
my_models:
    base_path: E:/AI_Models/
    checkpoints: checkpoints/
```

## 下一步

- 查看 [性能优化](04-性能优化.md) 提升生成效率
